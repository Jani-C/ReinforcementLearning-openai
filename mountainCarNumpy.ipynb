{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mountainCarNumpy.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jani-C/ReinforcementLearning-openai/blob/master/mountainCarNumpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08cRmtaLXcRo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "42c2fc4f-de59-4e87-bf4c-9c59f23c4220"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import numpy as np\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pos_space = np.linspace(-1.2, 0.6, 20)\n",
        "vel_space = np.linspace(-0.07, 0.07, 20)\n",
        "\n",
        "def get_state(observation):\n",
        "    \n",
        "    pos, vel = observation\n",
        "    pos_bin = np.digitize(pos, pos_space)\n",
        "    vel_bin = np.digitize(vel, vel_space)\n",
        "    \n",
        "    return (pos_bin, vel_bin)\n",
        "    print(pos_bin, vel_bin)\n",
        "\n",
        "def max_action(Q, state, actions = [0,1,2]):\n",
        "    \n",
        "    values = np.array(Q[state, a] for a in actions)\n",
        "    action = np.argmax(values)\n",
        "    \n",
        "    return(action)\n",
        "    print(action)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    env = gym.make('MountainCar-v0')\n",
        "    env._max_episode_steps = 1000\n",
        "    n_games = 5000\n",
        "    alpha = 0.1\n",
        "    gamma = 0.99\n",
        "    epsilon = 1.0\n",
        "    \n",
        "    states = []\n",
        "    for pos in range(21):\n",
        "        for vel in range(21):\n",
        "            states.append((pos, vel))\n",
        "            \n",
        "    Q = {}\n",
        "    for state in states:\n",
        "        for action in [0,1,2]:\n",
        "            Q[state, action] = 0\n",
        "    \n",
        "    score = 0\n",
        "    total_rewards = np.zeros(n_games)\n",
        "    for i in range(n_games):\n",
        "        done = False\n",
        "        obs = env.reset()\n",
        "        state = get_state(obs)\n",
        "        #print(obs, state)\n",
        "        if i % 100 == 0 and i > 0:\n",
        "            print('episode', i, 'score', score, 'epsilon %.3f', epsilon)\n",
        "        score = 0\n",
        "            \n",
        "        while not done:\n",
        "            action = np.random.choice([0,1,2]) if np.random.random() < epsilon \\\n",
        "                    else max_action (Q, state)\n",
        "            obs_, reward, done, info = env.step(action)\n",
        "            state_ = get_state(obs_)\n",
        "            score += reward\n",
        "            action_ = max_action(Q, state_)\n",
        "            Q[state, action] = Q[state, action] + alpha*(reward+ gamma*Q[state_, action_] - Q[state, action])\n",
        "            state = state_\n",
        "            \n",
        "        total_rewards[i] = score\n",
        "        epsilon = epsilon - 2/n_games if epsilon > 0.01 else 0.01\n",
        "        \n",
        "        mean_rewards = np.zeros(n_games)\n",
        "        for t in range(n_games):\n",
        "            mean_rewards[t] = np.mean(total_rewards[max(0, t-50):(t+1)])\n",
        "        plt.plot(mean_rewards)\n",
        "        plt.savefig('mountaincar.png')\n",
        "            #print(obs_, state_)\n",
        "            #input()\n",
        "        \n",
        "\n",
        "'''    numGames = 1000\n",
        "    rewards = np.zeros(numGames)\n",
        "    for i in range(numGames):\n",
        "        observation = env.reset()\n",
        "        done = False\n",
        "        epRewards = 0\n",
        "        while not done:\n",
        "            action = env.action_space.sample()\n",
        "            observation, reward, done, info = env.step(action)\n",
        "            epRewards += reward\n",
        "            #env.render()\n",
        "        rewards[i] = epRewards\n",
        "\n",
        "    plt.plot(rewards)\n",
        "    plt.show()'''\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "episode 3400 score -1000.0 epsilon %.3f 0.01\n",
            "episode 3400 score -1000.0 epsilon %.3f 0.01\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}